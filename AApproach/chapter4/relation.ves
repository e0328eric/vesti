It turns out that the investigation of general equation \cref{eq:simp-spde} with
coefficients independent of $x$ can be quite formally reduced to the particular
case of the heat equation. First, we explain how to do this without caring about
rigorousness, and then proceed with formal proofs.

The first observation consists of the following. Assume that we have
useenv equation { \label{eq:4.2.0.1}
    du(t,x) = f(t,x)dt + g^k(t,x)dw_t^k,
}
and we define a process $x_t$ and a function $v$ by
useenv equation { \label{eq:4.2.0.2}
    x_t^i = \int_0^t \sigma^{ik}(s)dw_s^k,\quad i=1,...,d,\quad
    v(t,x)=u(t,x-x_t).
}
We now apply formally the It\^o-Wentzell formula. The statement of which is
followed:
useenv prop { \label{prop:ito-wentzell}
    Let $\xi=\xi_t$ be a stochastic process with stochastic differential
    $$
        d\xi_t^i = b_t^idt + \sigma_t^{ik}dw_t^k,
    $$
    and let $F$ be a $\Pc\otimes\Bf(\R^d)$-measurable real-valued function
    belonging to $C^{0,2}([0,oo)\times\R^d)$ for (a.a.) $\omega$.
    Assume that, for every $x\in\R^d$, the function $F$ has a stochastic differential
    $$
        dF(t,x) = J(t,x)dt + H^k(t,x)w_t^k,
    $$
    where $J$, $H^k$, $k=1,...,d'$ are $\Pc\otimes\Bf(\R^d)$-measurable
    real-valued functions. We also assume that $H^k\in
    C^{0,1}([0,oo)\times\R^d)$ for all $k$ and (a.a.) $\omega$. Then the process
    $t|-> F(t,\xi_t)$ has a stochastic differential
    $$
        useenv aligned {
            dF(t,\xi_t) &= J(t,\xi_t)dt + H^k(t,\xi_t)dw_t^k \\
            &+?(b^iF_{x^i}(t,\xi_t)+{1//2}\sigma^{ik}\sigma^{jk}F_{x^ix^j}(t,\xi_t))?dt
            + \sigma^{ik}F_{x^i}(t,\xi_t)dw_t^k \\
            &+\sigma^{ik}H_{x^i}^k(t,\xi_t)dt.
        }
    $$
}
One can see its proof at \cite{RL}, and the distribution version is presented in
\cite{SF}. By applying It\^o-Wentzell's formula, we obtain
useenv equation { \label{eq:ito-wentzell}
useenv aligned {
    dv(t,x) &= [f(t,x-x_t) + \alpha^{ij}(t)v_{x^ix^j}(t,x) -
    (g_{x^i}(t,x-x_t),\sigma^i(t))_{l_2}]dt \\
    &\kern0.5cm+[g^k(t,x-x_t) - v_{x^i}(t,x)\sigma^{ik}(t)]dw_t^k.
}}
This shows how to introduce the terms $v_{x^i}\sigma^{ik}$ in equation
\cref{eq:4.2.0.1} and also shows again a kind of necessity for $g$ to have the
first derivatives in $x$.

This device alone is not sufficient, since, if we had $\Delta u + \bar f$
instead of $f$ in \cref{eq:4.2.0.1}, then, in \cref{eq:ito-wentzell}, we would
get the second order differential operator
$(\delta^{ij}+\alpha^{ij})\diff^2/\diff x^i\diff x^j$ with coefficients strongly
related to the coefficients of $v_{x^i}\sigma^{ik}(t)$.\footnote{
    Personally thinking, the term \lq\lq strongly related\rq\rq\ means between
    $u$ and $v$.
}
We could get around this difficulty if we manage to start with equations with
more general operators $L$ instead $\Delta$. Here the second observation comes
that if, instead of \cref{eq:4.2.0.1}, we consider
$$
    du(t,x) = (\Delta u + \bar f)dt + g^k(t,x)dw_t^k,
$$
and take expectations in the counterpart of \cref{eq:ito-wentzell} corresponding
to this equation, then, assuming that $\sigma$ is nonrandom, we get indeed an
equation for $\Eb v(t,x)$ with operator $L$ different from $\Delta$. By the way,
this method of studying parabolic equations with coefficients independent of $x$
was applied in \cite{Kry5} in order to show that \lq\lq whatever\rq\rq\ estimate
is true for the heat equation, it is also true for any parabolic equation with
coefficients independent of $x$. Of course, taking expectations \lq\lq
kills\rq\rq\ all randomness in the equation, and therefore we use a conditional
expectation.

useenv defin {
    Denote by $\Df$ the set of all $\Dc$-valued functions $u$ (written as
    $u(t,x)$ in a common abuse of notation) on $\Omega\times[0,oo)$ such that,
    for any $\phi\in C_0^oo$,
    useenv enumerate [label=(\roman*)] {
        \item the function $(u,\phi)$ is $\Pc$-measurable,
        \item for any $\omega\in\Omega$ and $T\in(0,oo)$, we have
        useenv equation { \label{eq:stochastic-distribution}
            \int_0^T \sup_{x\in\R^d}|(u(t,\cdot),\phi(\cdot-x))|^2dt < oo.
        }
    }
    In the same way, we define $\Df(l_2)$ by considering $l_2$-valued linear
    functionals on $C_0^oo$\footnote{
        A sequence $\Lambda=(\Lambda^k)_k$ of linear functionals on $C_0^oo$
        such that for every $\phi\in C_0^oo$,
        $$
            |(\Lambda,\phi)|_{l_2} \defeq \sum_{k=1}^oo (\Lambda^k,\phi)^2 < oo.
        $$
    } and replacing $|\cdot|$ in \cref{eq:stochastic-distribution} by $|\cdot|_{l_2}$.
}

useenv remark {
    Notice that $(u(t,\cdot),\phi(\cdot-x))$ is continuous in $x$ and Borel in
    $t$ so that \cref{eq:stochastic-distribution} makes sense. Also, for $p>=2$,
    $q=p/(p-1)$, and any $n$,
    useenv equation { \label{eq:4.2.5.1}
        \int_0^T\sup_{x\in\R^d}|(u(t,\cdot),\phi(\cdot-x))|^2dt
        <=\int_0^T||u(t,\cdot)||_{n,p}^2||\phi||_{-n,q}^2dt
        <= ||\phi||_{-n,q}^2?(\int_0^T||u(t,\cdot)||_{n,p}^pdt)?^{2/p}.
    }
    This shows that if $u\in\Hc_p^n$, then condition
    \cref{eq:stochastic-distribution} is satisfied at least for almost all
    $\omega$. Also, if $u\in\Hc_p^n$, then \cref{eq:3.1.1} holds, which shows
    that $(u(t,\cdot),\phi)$ is indistinguishable from a predictable
    process.\footnote{
        For fixed $t$, $(f(s,\cdot),\phi)$ is
        $\overline{\Fc_t\otimes\Bf([0,oo))}$ for every $s<=t$. Thus by the
        Fubnini's theorem and the fundamental theorem of calculus,
        $\int_0^t(f(s,\cdot),\phi)$ is $\Fc_t$-measurable (recall that it is
        complete) for each $t$ and continuous on every compact set in $t$, hence
        it is indistinguishable from a predictable process. For the stochastic
        part, it is a local martingale, so it is $\Fc_t$-adapted. Furthermore,
        it is continuous in $t$ (a.s.) where $\phi\in C_0^oo$ is fixed.
        Therefore, it also has a predictable representitive.
    }
    This is true for any $\phi\in C_0^oo$. From separability of $H_q^{-n}$, it
    follows that we can modify $u$ on a set of probability zero and after this
    we get a function belonging to $\Df$. This is the sense in which we write
    useenv equation { \label{eq:stochastic-function-space-relation}
        \Hc_p^n \subset\Df.
    }
}
useenv defin { \label{defin:stochastic-distribution-diff}
    Let $f,u\in\Df$, $g\in\Df(l_2)$. We say that the equality
    useenv equation { \label{eq:stochastic-distribution-diff}
        du(t,x) = f(t,x)dt + g(t,x)dw_t,\quad t>0,
    }
    holds \it{in the sense of distributions} if for any $\phi\in C_0^oo$, with
    probability 1 for all $t>=0$ we have
    useenv equation { \label{eq:stochastic-distribution-diff-cond}
        (u(t,\cdot),\phi) = (u(0,\cdot),\phi) + \int_0^t (f(s,\cdot),\phi)ds
        + \int_0^t (g^k(s,\cdot),\phi)dw_s^k,
    }
    or write in the differential form by
    $$
        d(u(t,\cdot),\phi) = (f(t,\cdot),\phi)dt + (g^k(t,\cdot),\phi)dw_t^k.
    $$
}

Observe that, since $|(g,\phi)(t)|_{l_2}^2$ is locally summable in $t$, the last
series in \cref{eq:stochastic-distribution-diff-cond} converges uniformly in $t$
on every finite interval of time in probability. This fact and
\cref{eq:stochastic-distribution} imply $(u(t,\cdot),\phi)\in
C_"loc"([0,oo))$ for (a.a.) $\omega$.

In this subsection, we always understand equation \cref{eq:simp-spde} in the
sense of distributions. Notice that if $u\in\Hc_p^n$ and $u$ satisfies
\cref{eq:stochastic-distribution-diff-cond}, then, by
\cref{eq:stochastic-function-space-relation}, $u\in\Df$ and
\cref{eq:stochastic-distribution-diff} holds in the sense of distributions. An
advantage of \Cref{defin:stochastic-distribution-diff} is that one need not
check summability of any derivative.\footnote{
    Recall the original definition of the stochastic differential (see
    \cite{Kry2}).
}

useenv lemma { \label{lemma:4.7}
    Let $f,u\in\Df$, $g\in\Df(l_2)$. Assume the definitions in
    \cref{eq:4.2.0.2}. Then \cref{eq:4.2.0.1} holds (in the sense of
    distributions) if and only if \cref{eq:ito-wentzell} holds (in the sense of
    distributions).
    \proof
    First remember that, for a distribution $\alpha(x)$ and $y\in\R^d$, by
    $\alpha(x-y)$ mean the distribution defined by $(\alpha,\phi(\cdot+y))$.
    Also from relations like (cf. \cref{eq:4.2.5.1})
    useenv align* {
        \int_0^T\sup_{y\in\R^d}|(v_{xx}(t,\cdot),\phi(\cdot-y))|^2dt
        &= \int_0^T\sup_{y\in\R^d}|(v(t,\cdot),\phi_{xx}(\cdot-y))|^2dt \\
        &= \int_0^T\sup_{y\in\R^d}|(u(t,\cdot),\phi_{xx}(\cdot+x_t-y))|^2dt \\
        &= \int_0^T\sup_{y\in\R^d}|(u(t,\cdot),\phi_{xx}(\cdot-y))|^2dt \\
        &< oo,
    }
    useenv align* {
        \int_0^T\sup_{y\in\R^d}
        |((g_{x^i}(t,\cdot-x_t),\sigma^i(t))_{l_2},\phi(\cdot-y))|^2 dt
        &= \int_0^T\sup_{y\in\R^d}
        |((g_{x^i}(t,\cdot-x_t), \phi(\cdot-y)),\sigma^i(t))_{l_2}|^2 dt \\
        &<= \sup_{t<=T}|\sigma^i(t)|_{l_2}^2
        \int_0^T\sup_{y\in\R^d}|(g_{x^i}(t,\cdot-x_t)\phi(\cdot-y))|_{l_2}^2dt
        < oo.
    }
    Here, by the elliptic condition, $\sigma^i(t)$ is uniformly bounded on each
    finite interval.
    It follows that $v(t,x)$, $f(t,x-x_t)$, and
    $(g_{x^i}(t,\cdot-x_t),\sigma^i(t))_{l_2}$ belong to $\Df$ and $g(t,x-x_t)$
    and $v_{x^i}(t,x)\sigma^i(t)$ belong to $\Df(l_2)$.
    Furthermore, for any $\phi\in C_0^oo$, the function $F(t,x)\defeq
    (u(t,\cdot-x),\phi)$ has a stochastic differential in $t$ for any $x$ and is
    infinitely differentiable with respect to $x$. Indeed, two parts are obvious
    by checking that $(u(t,\cdot-x),\phi) = (u(t,\cdot),\phi(\cdot + x))$, and
    clearly $(x,y) |-> \phi(y+x)$ is jointly infinitely differentiable.
    Now our assertion immediately follows from the real-valued It\^o-Wentzell
    formula for $F(t,x_t)$ (recall that for every $x$, $F(t,x)$ is continuous in
    $t$ (a.s.)). By the way, heuristically, one can easily memorize this formula
    by the considering the following computations.
    Write symbollically by
    $$
        \int_{\R^d}u(x)\phi(x)dx \defeq (u,\phi).
    $$
    Then
    useenv align* {
        d\int_{\R^d}u(t,x-x_t)\phi(x)dx
        &= d\int_{\R^d}u(t,x)\phi(x+x_t)dx \\
        &= \int_{\R^d}\phi(x+x_t)du(t,x)dx
        + \int_{\R^d}u(t,x)d\phi(x+x_t)dx
        + \int_{\R^d}(du(t,x))d\phi(x+x_t)dx \\
        &= ....
    }
}

useenv remark {
    If, instead of \cref{eq:4.2.0.1}, $u$ satisfies the equation
    $$
        du(t,x) = (a^{ij}(t)u_{x^ix^j}(t,x) + h(t,x))dt
        + \sigma^{ik}(t)u_{x^i}(t,x)dw_t^k,
    $$
    then \cref{eq:ito-wentzell} takes the form
    useenv equation { \label{eq:example-ill-posed}
        {\diff//\diff t}v(t,x) = ((a^{ij}(t) - \alpha^{ij}(t))v_{x^ix^j}(t,x)
        + h(t,x-x_t),\quad t>0,
    }
    and can be considered on each $\omega$ separately. Here, recall that
    $\alpha^{ij}(t) = (1/2)(\sigma^i(t),\sigma^j(t))_{l_2}$. Observe that if $a(t) <
    \alpha(t)$ (in the matrix sense), then the initial-value problem $v(0)=v_0$
    for equation \cref{eq:example-ill-posed} is \it{ill posed}.\footnote{
        The form of which is well-posed when the terminal-value is provided.
    }

    This shows that operators appearing in the stochastic term (the $\sigma$) should be
    subordinated in a certain sense to the operator in the deterministic part
    (the $a$) of the equation. This is needed in order to construct an
    $L_p$-theory. On the other hand, take $d=1$ and a one-dimensional Wiener
    process $w_t$. Consider the following equation
    $$
        du(t,x) = -iu_x(t,x)dw_t.
    $$
    Suprisingly enough and somewhat in spite of what is said above, this
    equation has a very nice solution for each initial data $u_0\in L_2$.
    One gets the solution after passing to Fourier transforms.
    It turns out that $\tilde u(t,x) = \tilde u_0(\xi)\exp[\xi w_t -
    (1/2)|\xi|^2t]$. The function $\tilde u(t,\xi)$ decays very fast when
    $|\xi| ->oo$, which shows that $u(t,x)$ is infinitely differentiable in $x$.
    Also notice that, taking expectations, we see that $\Eb u(t,x)=u_0(x)$ if
    $u_0$ is nonrandom\footnote{
        Indeed, for the SPDE,
        $$
            u(t,x) = u_0(x) - i\int_0^t u_x'(s,x)dw_s.
        $$
        Taking the expectation, we obtain the result.
    }, and in this case we get a representation of any $L_2$
    function as an integral over $\Omega$ of functions $u(\omega,1,x)$ which are
    infinitely differentiable in $x$.
    However, the major drawback of such equations is that $\Eb|u(t,0)|^p = oo$
    for any $p>1$ if, for example, $\tilde u_0(\xi)>=\exp(-\lambda|\xi|)$.\footnote{
        Recall that $u(t,0) = c\int_\R\tilde u(t,\xi)d\xi$ where $c>0$ is a
        constant. Using the fact
        $$
            \int_0^oo\exp(ax - bx^2)dx
            =
            {\sqrt{\pi}//2\sqrt{b}}\exp?({a^2//4b})?(1+"erf"?({a//2\sqrt{b}})?)
        $$
        where $b>0$ and $"erf"(x)\defeq 2\pi^{-1/2}\int_0^xe^{-t^2}dt$,
        one can easily derive the conclusion.
    }
}

useenv lemma { \label{lemma:4.9}
    Let $f\in\Df$, $g\in\Df(l_2)$, $u_0$ be a $\Dc$-valued function on $\Omega$.
    Then the following assertions hold:
    useenv enumerate [label=(\roman*)] {
        \item In $\Df$ there can exist only one (up to evanescence) solution of
        equation \cref{eq:simp-spde} with the initial condition
        $u(0,\cdot)=u_0$.
        \item Let $\Fc_t=\Wc_t\vee\Bc_t$ for $t>=0$, and assume that
        $\sigma$-fields $\Wc_t$ and $\Bc_t$ form independent increasing
        filtrations. Let $W$ and $B$ be sets such that $W\cup B=\Z_+$. Assume
        that $(w_t^k,\Wc_t)$ and $(w_t^r,\Bc_t)$ are Wiener processes for $k\in
        W$ and $r\in B$. Let $u\in\Df$ satisfy \cref{eq:simp-spde} (in the sense
        of distributions), and let $a,f,\sigma,g$ be $\Wc_t$-adapted. Finally,
        assume that there exists an $n\in(-oo,oo)$ such that $f\in\Hb_2^n(T)$,
        $g\in\Hb_2^n(T,l_2)$ for any $T\in(0,oo)$ and $u(0,\cdot)$ is
        $\Wc_0$-measurable and
        $$
            \Eb||u(0,\cdot)||_{n,2}^2 < oo.
        $$
        Then in $\Df$ there exists a unique solution $\tilde u$ of the equation
        useenv equation { \label{eq:lemma:4.9.1}
            d\tilde u = (a^{ij}\tilde u_{x^ix^j}+f)dt
            + \sum_{k\in W}(\sigma^{ik}\tilde u_{x^i}+g^k)dw_t^k,\quad t>0.
        }
        In addition, for any $\phi\in C_0^oo$ and $t>=0$,
        useenv equation { \label{eq:lemma:4.9.2}
            (\tilde u(t,\cdot),\phi) = \Eb[(u(t,\cdot),\phi)|\Wc_t]\quad
            "(a.s.)".
        }
    }
    \proof
    Beware that the proposition (i) proves that there exists \it{at most one}
    solution.
    As always, we can take $f\equiv 0$, $g\equiv 0$, and $u_0\equiv 0$ to prove
    the uniqueness. By \Cref{lemma:4.7}, it suffices to consider only the case
    $\sigma\equiv 0$. Indeed, \Cref{lemma:4.7} implies that the uniqueness of
    the equation
    $$
        du(t,x) = (a^{ij} - \alpha^{ij})(t)u_{x^ix^j}(t,x)dt,
        \quad \alpha^{ij} \defeq {1//2}(\sigma^i,\sigma^j)_{l_2},
    $$
    implies the uniqueness of the one what we want to prove.

    For any given $\phi\in C_0^oo$ then we have
    $$
        (u(t,\cdot),\phi) = \int_0^t (u(s,\cdot),\phi)ds,\quad t>=0,
    $$
    almost surely. Putting here $\phi(\cdot-x)$ instead of $\phi$ and observing
    that both sides are continuous and bounded in $(t,x)$ on $[0,T]\times\R^d$
    for any $T<oo$ (cf. \cref{eq:stochastic-distribution})\footnote{
        Here, continuity in $t$ follows from the integral form.
    }, we get that the
    function $F(t,x)\defeq (u(t,\cdot),\phi(\cdot-x))$ is bounded in $(t,x)$ on
    $[0,T]\times\R^d$ for any $T<oo$, infinitely differentiable in $x$, and
    satisfies the equation
    $$
        F(t,x) = \int_0^t L(s)F(s,x)ds\quad \forall t,x\ "(a.s.)".
    $$
    From the theory of parabolic equations, it follows that $F(t,x)=0$ for all
    $t,x$ (a.s.). This means that $(u(t,\cdot),\phi)=0$ for all $t$ (a.s.).
    Now take $\phi$ with unit integral. Then for any $x$ and $n$ with
    probability 1, $(u(t,\cdot),n^d\phi(n(\cdot-x)))=0$ for all $t$. Since this
    function is continuous in $x$, we have $(u(t,\cdot),n^d\phi(n(\cdot-x)))=0$
    for all $t$ and $x$ with probability 1. Finally,
    $(u(t,\cdot),n^d\phi(n(\cdot-x)))->u(t,x)$ as $n->oo$ for all
    $(\omega,t,x)$ in the sense of distributions, which implies that, with
    probability 1, we have $u(t,\cdot)=0$ for all $t$ as stated.

    \noindent (ii) First, notice that, according to Theorem 4.2 in \cite{RL},
    equation \cref{eq:simp-spde} has a unique solution $v$ in the space
    $\Hb_2^n(T)$ for any $T$.\footnote{
        Actually, the theorem in \cite{RL} only deals with finite sum of
        stochastic parts. Thus to apply the theorem, we need to be care of.
    }
    The definition of solutions $\Hb_2^{n+1}(T)$ from \cite{RL} is slightly
    different,\footnote{
        Our definition uses the distributional application, on the other hand,
        \cite{RL} uses $L_2$ inner product to describe the definition of the
        generalized solution. However, \cite{RL}'s definition implies our
        definition.
    } but $v$ is continuous (a.s.) as an $H_2^n$-valued process and
    useenv equation { \label{eq:lemma:4.9.3}
        \Eb\sup_{t<=T}||v(t,\cdot)||_{n,2}^n < oo,\quad \forall T<oo,
    }
    so that $v$ is a $\Df$-solution of \cref{eq:simp-spde}.
    It follows from (i) that our function $u$ coincides with $v$ and therefore
    belongs to $\Hb_2^{n+1}(T)$ for any $T$, and \cref{eq:lemma:4.9.3} holds for
    $u$. Furthermore, with probability 1 for all $t$ at once,
    $$
        u(t) = u(0) + \int_0^t[a^{ij}(s)u_{x^ix^j}(s) + f(s)]ds
        + \int_0^t [\sigma^{ik}(s)u_{x^i}(s)+g^k(s)]dw_s^k,
    $$
    where all integrals are taken in the sense of the Hilbert space $H_2^{n-1}$
    (see Theorem 2.8 of \cite{RL}).
    
    Now claim that there exists an $H_2^{n+1}$-valued, $\Wc_t$-predictable
    function $\bar u(t)$ such that, for almost any $t$, we have
    $$
        \bar u(t) = \Eb[u(t)|\Wc_t],\quad
        \bar u_{x}(t) = \Eb[u_{x}(t)|\Wc_t],\quad
        \bar u_{xx}(t) = \Eb[u_{xx}(t)|\Wc_t],\quad "(a.s.)"
    $$
    (conditional expectations of Hilbert-space valued random elements)\footnote{
        One can see \cite{RL} for its definition, which is, let $\xi$ be a
        random element valued at some Hilbert space $H$, and $\Gc$ be sub
        $\sigma$-field of $\Fc$ where $(\Omega,\Fc,\Pb)$ is given. Then
        $\Eb[\xi|\Gc]$ is defined by that for every $\Lambda\in H^*$,
        $$
            \Lambda\Eb[\xi|\Gc] = \Eb[\Lambda\xi|\Gc]\quad "(a.s.)".
        $$
    } and
    useenv equation { \label{eq:lemma:4.9.4}
        \bar u(t) = u(0) + \int_0^t[a^{ij}(s)\bar u_{x^ix^j}(s) + f(s)]ds
        + \sum_{k\in W}\int_0^t[\sigma^{ik}(s)\bar u_{x^i}(s) + g^k(s)]dw_s^k
    }
    for almost all $t$ and $\omega$. The core part is proved in
    \Cref{lemma:lemma:4.9}.\footnote{
        In the original paper, it refers Theorem 1.15 in \cite{RL}. However we
        cannot use the theorem directly because $\sigma$-fields are quite
        different.
    }
    useenv center {
        \bf{\color{red}[Fill out the gap]}
    }
    The right hand side of \cref{eq:lemma:4.9.4} is continuous
    $H_2^{n-1}$-valued process which we denote by $\tilde u$ and we show that
    $\tilde u$ is the function we need.

    By definition and by the equality $\bar u = \tilde u$ (a.e.), $\tilde u$
    satisfies \cref{eq:lemma:4.9.4} for all $t$ with probability 1 and also is a
    continuous process in $H_2^{n-1}$. This implies that $\tilde u\in\Df$ and
    $\tilde u$ is a solution of \cref{eq:lemma:4.9.1}.
    useenv center {
        \bf{\color{red}[Fill out the gap]}
    }
}

